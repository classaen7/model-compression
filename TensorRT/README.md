# TensorRT
TensorRTëŠ” í•™ìŠµëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ìµœì í™”í•˜ì—¬ Nvidia GPU ìƒì—ì„œ Inference ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” ëª¨ë¸ ìµœì í™” ì—”ì§„ì´ë‹¤.<br>
pytorch, tensorflow, mxnet ë“± ë‹¤ì–‘í•œ frameworkë¥¼ ì§€ì›í•œë‹¤.

# 5ê°€ì§€ ëª¨ë¸ ìµœì í™” ê¸°ë²•
![title](https://github.com/user-attachments/assets/f32743de-1d13-4ae2-a5fe-edd642494909)   <br>
í•™ìŠµëœ ëª¨ë¸ì´ ë“¤ì–´ì˜¤ë©´ ìœ„ì™€ ê°™ì€ ê¸°ë²•ì„ ì‚¬ìš©í•´ì„œ ëª¨ë¸ ìµœì í™”ë¥¼ ìˆ˜í–‰í•œë‹¤.

# ONNX
TensorRTëŠ” ì¼ë°˜ì ìœ¼ë¡œ ONNXë¥¼ ê±°ì³ì„œ ìˆ˜í–‰ëœë‹¤.

> **ONNX**<br>
ONNX(Open Neural Network Exchange)ëŠ” ê·¸ë˜í”„ì˜ ê³µí†µëœ í‘œí˜„(operator)ë¥¼ ì œê³µí•˜ì—¬ í”„ë ˆì„ì›Œí¬ ê°„ì˜ ë³€í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì—ì„œ ìƒì„±ëœ ëª¨ë¸ì´ ìƒí˜¸ í˜¸í™˜ë  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì´ë‹¤.<br>

# PyTorch â†’ ONNX
PytorchëŠ” ëŒ€ë¶€ë¶„ì˜ layerì— ëŒ€í•´ onnx exportë¥¼ ì§€ì›í•œë‹¤.<br>
ONNXë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ì„  ëª¨ë¸ì˜ ì…ë ¥ ë°ì´í„° í¬ê¸°ë¥¼ ë„˜ê²¨ì£¼ì–´ì•¼ í•œë‹¤.
<font color="gray"> ì§€ì›í•˜ì§€ ì•ŠëŠ” operatorì— ëŒ€í•œ ìˆ™ì§€ê°€ í•„ìš”í•˜ë‹¤. </font>

``` py
# ëª¨ë¸ì— ëŒ€í•œ ì…ë ¥ê°’
x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)
torch_out = torch_model(x)

# ëª¨ë¸ ë³€í™˜
torch.onnx.export(torch_model,               # ì‹¤í–‰ë  ëª¨ë¸
                  x,                         # ëª¨ë¸ ì…ë ¥ê°’ (íŠœí”Œ ë˜ëŠ” ì—¬ëŸ¬ ì…ë ¥ê°’ë“¤ë„ ê°€ëŠ¥)
                  "super_resolution.onnx",   # ëª¨ë¸ ì €ì¥ ê²½ë¡œ (íŒŒì¼ ë˜ëŠ” íŒŒì¼ê³¼ ìœ ì‚¬í•œ ê°ì²´ ëª¨ë‘ ê°€ëŠ¥)
                  export_params=True,        # ëª¨ë¸ íŒŒì¼ ì•ˆì— í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í• ì§€ì˜ ì—¬ë¶€
                  opset_version=10,          # ëª¨ë¸ì„ ë³€í™˜í•  ë•Œ ì‚¬ìš©í•  ONNX ë²„ì „
                  do_constant_folding=True,  # ìµœì í™”ì‹œ ìƒìˆ˜í´ë”©ì„ ì‚¬ìš©í• ì§€ì˜ ì—¬ë¶€
                  input_names = ['input'],   # ëª¨ë¸ì˜ ì…ë ¥ê°’ì„ ê°€ë¦¬í‚¤ëŠ” ì´ë¦„
                  output_names = ['output'], # ëª¨ë¸ì˜ ì¶œë ¥ê°’ì„ ê°€ë¦¬í‚¤ëŠ” ì´ë¦„
                  dynamic_axes={'input' : {0 : 'batch_size'},    # ê°€ë³€ì ì¸ ê¸¸ì´ë¥¼ ê°€ì§„ ì°¨ì›
                                'output' : {0 : 'batch_size'}})
```

# TensorRT ë³€í™˜ê³¼ì •
![title](https://github.com/user-attachments/assets/dcaaafe5-7fcc-4ec7-88d7-f37e5c79c65e)   <br>
ğŸ”—[ìì„¸í•œ Step í™•ì¸í•˜ê¸°](https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html)   

TensorRTëŠ” ìœ„ì²˜ëŸ¼ 5ë‹¨ê³„ì˜ ë³€í™˜ ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.<br>
<font color="gray">Select A Precision : float32, float16, int8ì„ ì„¤ì • (int8ì—ì„œëŠ” calibrationì´ í•„ìš”)</font><br>

# ONNX â†’ TensorRT : CLI (trtexec)
ë³„ë„ì˜ ì½”ë“œ ì—†ì´ CLI íˆ´ì„ ì‚¬ìš©í•˜ì—¬ ì‰½ê²Œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤. <br>

`trtexec`ë¼ëŠ” ì»¤ë§¨ë“œë¥¼ ì‹œì‘ìœ¼ë¡œ ë‹¤ì–‘í•œ ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¥¼ ë„£ì–´ì¤Œìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. <br>
```
trtexec --onnx=export/test_model.onnx --workspace=8000
        --maxBatch=16 --saveEngine=export/cli_test_model_float16.trt 
        --float16 --dumpProfile --verbose
```
CLI argsëŠ” `trtexec --help`ë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ìˆë‹¤.


# ONNX â†’ TensorRT : API
`trtexec`ì—ì„œ ì‚¬ìš©í•œ ì¸ìë“¤ì„ ì½”ë“œ ë‚´ì—ì„œ ì„¤ì •í•˜ì—¬ ì„¸íŒ…í•  ìˆ˜ ìˆë‹¤. <br>
ONNXì—ì„œ TensorRTì˜ ë³€í™˜ ì›Œí¬í”Œë¡œìš°ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.<br>
![title](https://github.com/user-attachments/assets/a2f086e4-72d5-4ea5-b54f-b7fbb82c9c2a) <br>

TensorRTëŠ” builderë¥¼ í†µí•´ íŠ¹ì • í”„ë ˆì„ì›Œí¬ë¡œ ì •ì˜ëœ Networkë¥¼ ì§ë ¬í™”(Serialize)ë¥¼ ìˆ˜í–‰í•˜ì—¬ Engineì„ ìƒì„±í•œë‹¤. <br>
ìƒì„±ëœ Engineì„ ê°€ì§€ê³  Runtimeì„ ìˆ˜í–‰í•œë‹¤.

- ì˜ˆì‹œ ì½”ë“œ
```py
# TensorRT ë³€í™˜ì¤€ë¹„, ë³€í™˜ ê´€ë ¨ class ì •ì˜
import onnx
import tensorrt as trt

# ë³€í™˜ëœ ONNX ëª¨ë¸ Load
with open("onnx_model.onnx", "rb") as f:
    onnx_data = f.read()

# ëª¨ë¸ ì…ë ¥ ë°ì´í„° í¬ê¸° ì„¤ì •
network_input_shape = (8, 3, 32, 32) # NCHW

# TensorRT ë¡œê±° ì„¸íŒ…(ë””ë²„ê¹… ëª©ì )
trt_logger = trt.Logger(trt.Logger.VERBOSE)

# Batch Size í¬ê¸° ì„¤ì •
explicit_batch = [
    1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
]

# builder: ëª¨ë¸ ë³€í™˜, network: ëª¨ë¸ ì •ì˜, parser: ONNX ëª¨ë¸ parser íŒŒì‹±ëœ ëª¨ë¸ì„ networkë¡œ ì „ë‹¬
with trt.Builder(trt_logger) as builder, builder.create_network(
    *explicit_batch
) as network, trt.OnnxParser(network, trt_logger) as parser:
    ......
```

```py
# ëª¨ë¸ ë³€í™˜ íŒŒë¼ë¯¸í„° ì„¤ì •, ëª¨ë¸ ë³€í™˜
with trt.Builder(trt_logger) as builder, builder.create_network(
    *explicit_batch
) as network, trt.OnnxParser(network, trt_logger) as parser:
    ......

with trt.Builder(trt_logger) as builder, builder.create_network(
        *explicit_batch)
as network, trt.OnnxParser(network, trt_logger) as parser: 
    parser.parse(onnx_data)
    network.get_input(0).shape = (self.batch_size,) + \ 
        network.get_input(0).shape[1:]
    builder.max_batch_size = 1

    config = builder.create_builder_config() 
    # GPU ìµœëŒ€ ë©”ëª¨ë¦¬ í• ë‹¹ëŸ‰ ì„¤ì •
    config.max_workspace_size = 8 << 30 # 8GiB GPU memory. 
    config.set_flag(trt.BuilderFlag.GPU_FALLBACK) 
    # FP16 ë³€í™˜ í”Œë˜ê·¸ ì„¤ì •
    config.set_flag(trt.BuilderFlag.FP16) 

    profile = builder.create_optimization_profile() 
    # ëª¨ë¸ ìµœì í™” í”„ë¡œíŒŒì¼ë¦¬ ì„¤ì •
    profile.set_shape( "images", network_input_shape, network_input_shape, network_input_shape )
    config.add_optimization_profile(profile)
    # Networkì™€ configë¥¼ builderì—ê²Œ ì „ë‹¬í•˜ì—¬ TensorRT ëª¨ë¸ ë³€í™˜
    # (ëª¨ë¸ ìµœì í™” ìˆ˜í–‰ê³¼ ë™ì‹œì— ê° GPUì— ìµœì í™”ëœ ì—°ì‚°ìë¥¼ ì´ìš©í•˜ë„ë¡ ë³€í™˜ë¨)
    engine = builder.build_engine(network, config)
```

```py
# Int8 quantization
# int8 calibrationì„ ìœ„í•œ ì´ë¯¸ì§€ í•„ìšœ
# cache_fileì´ ì—†ëŠ” ê²½ìš° imt_dir ë‚´ì˜ ì´ë¯¸ì§€ë¥¼ í†µí•˜ì—¬
# calibrationì„ ìˆ˜í–‰í•˜ê³ , cacheë¥¼ ìƒì„±
int8_calibrator = Int8Calibrator(
        img_dir="calibration/image/path",
        img_extension="png",
        batch_size=32,
        preprocess_type="CIFAR10",
        cache_file="export/int8_cache.bin",
)

profile.set_shape(
        "images", 
        network_input_shape,
        network_input_shape,
        network_input_shape
)
# Config ë‚´ì— int 8 flagì™€ int8_calibratorë¥¼ ì„¤ì •
config.set_flag(trt.BuilderFlag.INT8)
config.int8_calibrator = int8_calibrator
config.set_calibration_profile(profile)
config.add_optimization_profile(profile)
engine = builder.build_engine(network, config)
```

# ğŸ”— Reference
[NVIDIA Developer](https://developer.nvidia.com/)  <br>
[NVIDIA TENSORRT DOCUMENTATION](https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html)   <br>
[PyTorch ëª¨ë¸ì„ ONNXìœ¼ë¡œ ë³€í™˜í•˜ê³  ONNX ëŸ°íƒ€ì„ì—ì„œ ì‹¤í–‰í•˜ê¸°](https://tutorials.pytorch.kr/advanced/super_resolution_with_onnxruntime.html)   <br>
[trtexec github](https://github.com/NVIDIA/TensorRT/tree/main/samples/trtexec)   

