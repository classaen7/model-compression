# model-compression
다양한 모델 경량화 기법에 대해 공부한 내용(이론&코드)을 정리하는 레포입니다.

### 경량화 필요성
1. 하드웨어 제약
2. 클라우드의 Latency & Throughput
3. 딥러닝 모델 연산량의 증가

### 경량화 분야
- Efficient Architecture Design
  - AutoML
- Matrix/Tensor Decomposition
- Network Quantization
- Network Compiling

- Network Pruning
- Knowledge Distillation






### 🔗 Reference

[boostcourse 딥러닝 모델 더 작게 만들기(경량화)](https://www.boostcourse.org/ai302/joinLectures/374476)

